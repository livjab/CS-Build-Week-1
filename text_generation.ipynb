{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Structure name</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1x1_a1</td>\n",
       "      <td>A room that is empty except for a bench on whi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(\"Flower room\")</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1x1_a2</td>\n",
       "      <td>A room with a cobblestone ring around the wall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(\"Rails and ladder room\")</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1x1_a3</td>\n",
       "      <td>A room with two types of tables made out of co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>(\"Office\")</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1x1_a4</td>\n",
       "      <td>A room with a checkerboard pattern on the floo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>(\"Checkerboard room\")</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1x1_a5</td>\n",
       "      <td>A room with cobblestone and a single flower po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>(\"White tulip sanctuary room\")</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Structure name  \\\n",
       "1                           1x1_a1   \n",
       "2                  (\"Flower room\")   \n",
       "9                           1x1_a2   \n",
       "15       (\"Rails and ladder room\")   \n",
       "16                          1x1_a3   \n",
       "22                      (\"Office\")   \n",
       "23                          1x1_a4   \n",
       "29           (\"Checkerboard room\")   \n",
       "30                          1x1_a5   \n",
       "36  (\"White tulip sanctuary room\")   \n",
       "\n",
       "                                          Description  \n",
       "1   A room that is empty except for a bench on whi...  \n",
       "2                                                 NaN  \n",
       "9   A room with a cobblestone ring around the wall...  \n",
       "15                                                NaN  \n",
       "16  A room with two types of tables made out of co...  \n",
       "22                                                NaN  \n",
       "23  A room with a checkerboard pattern on the floo...  \n",
       "29                                                NaN  \n",
       "30  A room with cobblestone and a single flower po...  \n",
       "36                                                NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"adventure_game.csv\")\n",
    "df = df.drop(columns=[\"Consists of\", \"[hide]Images\"])\n",
    "df = df.drop([0])\n",
    "df = df.dropna(how='all')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Structure name</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1x1_a1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(\"Flower room\")</td>\n",
       "      <td>A room that is empty except for a bench on whi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1x1_a2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(\"Rails and ladder room\")</td>\n",
       "      <td>A room with a cobblestone ring around the wall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1x1_a3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>(\"Office\")</td>\n",
       "      <td>A room with two types of tables made out of co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1x1_a4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>(\"Checkerboard room\")</td>\n",
       "      <td>A room with a checkerboard pattern on the floo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1x1_a5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>(\"White tulip sanctuary room\")</td>\n",
       "      <td>A room with cobblestone and a single flower po...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Structure name  \\\n",
       "1                           1x1_a1   \n",
       "2                  (\"Flower room\")   \n",
       "9                           1x1_a2   \n",
       "15       (\"Rails and ladder room\")   \n",
       "16                          1x1_a3   \n",
       "22                      (\"Office\")   \n",
       "23                          1x1_a4   \n",
       "29           (\"Checkerboard room\")   \n",
       "30                          1x1_a5   \n",
       "36  (\"White tulip sanctuary room\")   \n",
       "\n",
       "                                          Description  \n",
       "1                                                 NaN  \n",
       "2   A room that is empty except for a bench on whi...  \n",
       "9                                                 NaN  \n",
       "15  A room with a cobblestone ring around the wall...  \n",
       "16                                                NaN  \n",
       "22  A room with two types of tables made out of co...  \n",
       "23                                                NaN  \n",
       "29  A room with a checkerboard pattern on the floo...  \n",
       "30                                                NaN  \n",
       "36  A room with cobblestone and a single flower po...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Description\"] = df[\"Description\"].shift(periods=1)\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Structure name</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Flower room</td>\n",
       "      <td>A room that is empty except for a bench on whi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Rails and ladder room</td>\n",
       "      <td>A room with a cobblestone ring around the wall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Office</td>\n",
       "      <td>A room with two types of tables made out of co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Checkerboard room</td>\n",
       "      <td>A room with a checkerboard pattern on the floo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>White tulip sanctuary room</td>\n",
       "      <td>A room with cobblestone and a single flower po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>X room</td>\n",
       "      <td>A secret room with walls lined with cobbleston...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Spider room</td>\n",
       "      <td>A secret room filled with many cobwebs and a s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Obsidian room</td>\n",
       "      <td>A secret room with an octahedron-shaped mass o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Birch pillar room</td>\n",
       "      <td>A secret room with 4 birch plank pillars that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Birch arch</td>\n",
       "      <td>An office-like room with a desk with a flower ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Small dining room</td>\n",
       "      <td>A small dining room or meeting room, with a ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Single bed bedroom</td>\n",
       "      <td>A cozy bedroom with a bed (made out of wool), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Small library</td>\n",
       "      <td>A small library or study room, the only things...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>Allium room</td>\n",
       "      <td>A room with a small vine-decorated oak stand, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>Gray banner room</td>\n",
       "      <td>An altar-like room with a construction in the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>Wheat farm</td>\n",
       "      <td>A room with a wheat farm, and a small table wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>Blacksmith room</td>\n",
       "      <td>A room with arches made of polished andesite. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>Sapling farm room</td>\n",
       "      <td>A room with 2 layers of rows of dark oak sapli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>Wool room</td>\n",
       "      <td>A room filled with a pile of assorted blue, li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>Tree chopping room</td>\n",
       "      <td>A room containing a tree and a chest which alw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>Mushroom farm</td>\n",
       "      <td>A room with a mushroom farm, as well as a tabl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>Stem farm</td>\n",
       "      <td>A room with a two-stage, pumpkin and melon far...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>Small empty storage room</td>\n",
       "      <td>A storage room with a lot of single chests. Al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>Redstone jail</td>\n",
       "      <td>A room with a door-opening redstone circuit. T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>Small jail</td>\n",
       "      <td>A room with a cell with cobblestone walls and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>Wood archway room</td>\n",
       "      <td>A room with a bunch of arches made of dark oak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>Winding stairway room</td>\n",
       "      <td>A room with spiral staircase: a 1-wide, dead e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>Illager head room</td>\n",
       "      <td>An otherwise empty room containing some illage...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>Curved stairs room</td>\n",
       "      <td>Some stairs leading up, decorated with an illa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>Medium dining room</td>\n",
       "      <td>A dining room, with a table with a flower pot ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>Double bed bedroom</td>\n",
       "      <td>A long bedroom with pink and purple beds towar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>Triple bed bedroom</td>\n",
       "      <td>A room with 3 blue beds and a desk. Three Vind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>Medium library</td>\n",
       "      <td>A lounge-like room with many bookcases, swing-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>Straight stairs room</td>\n",
       "      <td>A straight staircase leading up, above which i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>Master bedroom</td>\n",
       "      <td>A large master bedroom with a regal bed. Banne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>Bedroom with loft</td>\n",
       "      <td>An interesting two-tiered bedroom, containing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>Altar room</td>\n",
       "      <td>A complex shrine-like room with a single promi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>Cat statue room</td>\n",
       "      <td>A room dedicated to a large black wool cat sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>Chicken statue room</td>\n",
       "      <td>A room dedicated to a large wool chicken statu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>Clean chest room</td>\n",
       "      <td>A secret room with 1 chest containing assorted...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>Fake end portal room</td>\n",
       "      <td>A secret room with a platform of orange wool i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>Roof-chests room</td>\n",
       "      <td>A secret room that is empty, and the walls hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>Large jail</td>\n",
       "      <td>A room with four cells with cobblestone walls ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>Large empty storage room</td>\n",
       "      <td>A room with a lot of double chests. The chests...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>Illager statue room</td>\n",
       "      <td>A room with a giant illager statue made out of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>Nature room</td>\n",
       "      <td>A room where in one corner has a flowing water...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>Large dining room</td>\n",
       "      <td>A large dining hall. Multiple three-chair tabl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>Conference room</td>\n",
       "      <td>A large gathering hall with a table in a U-sha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>Large library</td>\n",
       "      <td>A large library/study room with three rows of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>Map room</td>\n",
       "      <td>A room with a colored carpet on the table, see...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>Arena room</td>\n",
       "      <td>A room with an arena/stage surrounded with dar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>Lava room</td>\n",
       "      <td>A secret room with a large glass case full of ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Structure name  \\\n",
       "2                   Flower room   \n",
       "15        Rails and ladder room   \n",
       "22                       Office   \n",
       "29            Checkerboard room   \n",
       "36   White tulip sanctuary room   \n",
       "43                       X room   \n",
       "50                  Spider room   \n",
       "57                Obsidian room   \n",
       "64            Birch pillar room   \n",
       "71                   Birch arch   \n",
       "78            Small dining room   \n",
       "86           Single bed bedroom   \n",
       "96                Small library   \n",
       "103                 Allium room   \n",
       "110            Gray banner room   \n",
       "117                  Wheat farm   \n",
       "129             Blacksmith room   \n",
       "136           Sapling farm room   \n",
       "143                   Wool room   \n",
       "150          Tree chopping room   \n",
       "157               Mushroom farm   \n",
       "166                   Stem farm   \n",
       "181    Small empty storage room   \n",
       "188               Redstone jail   \n",
       "199                  Small jail   \n",
       "213           Wood archway room   \n",
       "220       Winding stairway room   \n",
       "227           Illager head room   \n",
       "234          Curved stairs room   \n",
       "247          Medium dining room   \n",
       "256          Double bed bedroom   \n",
       "264          Triple bed bedroom   \n",
       "271              Medium library   \n",
       "280        Straight stairs room   \n",
       "293              Master bedroom   \n",
       "306           Bedroom with loft   \n",
       "318                  Altar room   \n",
       "327             Cat statue room   \n",
       "334         Chicken statue room   \n",
       "341            Clean chest room   \n",
       "348        Fake end portal room   \n",
       "355            Roof-chests room   \n",
       "362                  Large jail   \n",
       "374    Large empty storage room   \n",
       "381         Illager statue room   \n",
       "390                 Nature room   \n",
       "397           Large dining room   \n",
       "409             Conference room   \n",
       "418               Large library   \n",
       "425                    Map room   \n",
       "436                  Arena room   \n",
       "446                   Lava room   \n",
       "\n",
       "                                           Description  \n",
       "2    A room that is empty except for a bench on whi...  \n",
       "15   A room with a cobblestone ring around the wall...  \n",
       "22   A room with two types of tables made out of co...  \n",
       "29   A room with a checkerboard pattern on the floo...  \n",
       "36   A room with cobblestone and a single flower po...  \n",
       "43   A secret room with walls lined with cobbleston...  \n",
       "50   A secret room filled with many cobwebs and a s...  \n",
       "57   A secret room with an octahedron-shaped mass o...  \n",
       "64   A secret room with 4 birch plank pillars that ...  \n",
       "71   An office-like room with a desk with a flower ...  \n",
       "78   A small dining room or meeting room, with a ta...  \n",
       "86   A cozy bedroom with a bed (made out of wool), ...  \n",
       "96   A small library or study room, the only things...  \n",
       "103  A room with a small vine-decorated oak stand, ...  \n",
       "110  An altar-like room with a construction in the ...  \n",
       "117  A room with a wheat farm, and a small table wi...  \n",
       "129  A room with arches made of polished andesite. ...  \n",
       "136  A room with 2 layers of rows of dark oak sapli...  \n",
       "143  A room filled with a pile of assorted blue, li...  \n",
       "150  A room containing a tree and a chest which alw...  \n",
       "157  A room with a mushroom farm, as well as a tabl...  \n",
       "166  A room with a two-stage, pumpkin and melon far...  \n",
       "181  A storage room with a lot of single chests. Al...  \n",
       "188  A room with a door-opening redstone circuit. T...  \n",
       "199  A room with a cell with cobblestone walls and ...  \n",
       "213  A room with a bunch of arches made of dark oak...  \n",
       "220  A room with spiral staircase: a 1-wide, dead e...  \n",
       "227  An otherwise empty room containing some illage...  \n",
       "234  Some stairs leading up, decorated with an illa...  \n",
       "247  A dining room, with a table with a flower pot ...  \n",
       "256  A long bedroom with pink and purple beds towar...  \n",
       "264  A room with 3 blue beds and a desk. Three Vind...  \n",
       "271  A lounge-like room with many bookcases, swing-...  \n",
       "280  A straight staircase leading up, above which i...  \n",
       "293  A large master bedroom with a regal bed. Banne...  \n",
       "306  An interesting two-tiered bedroom, containing ...  \n",
       "318  A complex shrine-like room with a single promi...  \n",
       "327  A room dedicated to a large black wool cat sta...  \n",
       "334  A room dedicated to a large wool chicken statu...  \n",
       "341  A secret room with 1 chest containing assorted...  \n",
       "348  A secret room with a platform of orange wool i...  \n",
       "355  A secret room that is empty, and the walls hav...  \n",
       "362  A room with four cells with cobblestone walls ...  \n",
       "374  A room with a lot of double chests. The chests...  \n",
       "381  A room with a giant illager statue made out of...  \n",
       "390  A room where in one corner has a flowing water...  \n",
       "397  A large dining hall. Multiple three-chair tabl...  \n",
       "409  A large gathering hall with a table in a U-sha...  \n",
       "418  A large library/study room with three rows of ...  \n",
       "425  A room with a colored carpet on the table, see...  \n",
       "436  A room with an arena/stage surrounded with dar...  \n",
       "446  A secret room with a large glass case full of ...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Structure name'] = df['Structure name'].map(lambda x: x.lstrip('(\"').rstrip('\")'))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52, 2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now that data is clean and ready, work on initial LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "\n",
    "text = df[\"Description\"].str.cat(sep=' ')\n",
    "text = text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating character/word mappings\n",
    "\n",
    "characters = sorted(list(set(text)))\n",
    "n_to_char = {n:char for n, char in enumerate(characters)}\n",
    "char_to_n = {char:n for n, char in enumerate(characters)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "length = len(text)\n",
    "seq_length = 100\n",
    "for i in range(0, length-seq_length, 1):\n",
    "    sequence = text[i:i + seq_length]\n",
    "    label =text[i + seq_length]\n",
    "    X.append([char_to_n[char] for char in sequence])\n",
    "    Y.append(char_to_n[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_modified = np.reshape(X, (len(X), seq_length, 1))\n",
    "X_modified = X_modified / float(len(characters))\n",
    "Y_modified = np_utils.to_categorical(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modeling\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(400, input_shape=(X_modified.shape[1], X_modified.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(400, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(400))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(Y_modified.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1023 22:55:58.471351 4350342592 deprecation.py:323] From /Users/ljohnson/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7514/7514 [==============================] - 382s 51ms/step - loss: 2.9768\n",
      "Epoch 2/100\n",
      "7514/7514 [==============================] - 368s 49ms/step - loss: 2.9206\n",
      "Epoch 3/100\n",
      "7514/7514 [==============================] - 345s 46ms/step - loss: 2.9101\n",
      "Epoch 4/100\n",
      "7514/7514 [==============================] - 341s 45ms/step - loss: 2.9771\n",
      "Epoch 5/100\n",
      "7514/7514 [==============================] - 344s 46ms/step - loss: 2.9255\n",
      "Epoch 6/100\n",
      "7514/7514 [==============================] - 343s 46ms/step - loss: 2.9159\n",
      "Epoch 7/100\n",
      "7514/7514 [==============================] - 343s 46ms/step - loss: 2.9113\n",
      "Epoch 8/100\n",
      "7514/7514 [==============================] - 342s 46ms/step - loss: 2.9119\n",
      "Epoch 9/100\n",
      "7514/7514 [==============================] - 346s 46ms/step - loss: 2.9083\n",
      "Epoch 10/100\n",
      "7514/7514 [==============================] - 338s 45ms/step - loss: 2.9072\n",
      "Epoch 11/100\n",
      "7514/7514 [==============================] - 345s 46ms/step - loss: 2.9083\n",
      "Epoch 12/100\n",
      "7514/7514 [==============================] - 341s 45ms/step - loss: 2.9080\n",
      "Epoch 13/100\n",
      "7514/7514 [==============================] - 339s 45ms/step - loss: 2.9068\n",
      "Epoch 14/100\n",
      "7514/7514 [==============================] - 340s 45ms/step - loss: 2.9039\n",
      "Epoch 15/100\n",
      "7514/7514 [==============================] - 338s 45ms/step - loss: 2.9037\n",
      "Epoch 16/100\n",
      "7514/7514 [==============================] - 338s 45ms/step - loss: 2.9068\n",
      "Epoch 17/100\n",
      "7514/7514 [==============================] - 337s 45ms/step - loss: 2.9039\n",
      "Epoch 18/100\n",
      "7514/7514 [==============================] - 338s 45ms/step - loss: 2.9061\n",
      "Epoch 19/100\n",
      "7514/7514 [==============================] - 339s 45ms/step - loss: 2.9031\n",
      "Epoch 20/100\n",
      "7514/7514 [==============================] - 338s 45ms/step - loss: 2.9040\n",
      "Epoch 21/100\n",
      "7514/7514 [==============================] - 339s 45ms/step - loss: 2.9036\n",
      "Epoch 22/100\n",
      "7514/7514 [==============================] - 339s 45ms/step - loss: 2.9025\n",
      "Epoch 23/100\n",
      "7514/7514 [==============================] - 338s 45ms/step - loss: 2.9044\n",
      "Epoch 24/100\n",
      "7514/7514 [==============================] - 338s 45ms/step - loss: 2.9025\n",
      "Epoch 25/100\n",
      "7514/7514 [==============================] - 343s 46ms/step - loss: 2.9046\n",
      "Epoch 26/100\n",
      "7514/7514 [==============================] - 329s 44ms/step - loss: 2.9023\n",
      "Epoch 27/100\n",
      "7514/7514 [==============================] - 329s 44ms/step - loss: 2.9029\n",
      "Epoch 28/100\n",
      "7514/7514 [==============================] - 333s 44ms/step - loss: 2.9026\n",
      "Epoch 29/100\n",
      "7514/7514 [==============================] - 331s 44ms/step - loss: 2.9028\n",
      "Epoch 30/100\n",
      "7514/7514 [==============================] - 330s 44ms/step - loss: 2.9005\n",
      "Epoch 31/100\n",
      "7514/7514 [==============================] - 330s 44ms/step - loss: 2.8942\n",
      "Epoch 32/100\n",
      "7514/7514 [==============================] - 330s 44ms/step - loss: 2.8805\n",
      "Epoch 33/100\n",
      "7514/7514 [==============================] - 331s 44ms/step - loss: 2.8617\n",
      "Epoch 34/100\n",
      "7514/7514 [==============================] - 332s 44ms/step - loss: 2.8385\n",
      "Epoch 35/100\n",
      "7514/7514 [==============================] - 331s 44ms/step - loss: 2.7973\n",
      "Epoch 36/100\n",
      "7514/7514 [==============================] - 334s 44ms/step - loss: 2.7462\n",
      "Epoch 37/100\n",
      "7514/7514 [==============================] - 331s 44ms/step - loss: 2.7016\n",
      "Epoch 38/100\n",
      "7514/7514 [==============================] - 333s 44ms/step - loss: 2.6744\n",
      "Epoch 39/100\n",
      "7514/7514 [==============================] - 330s 44ms/step - loss: 2.6440\n",
      "Epoch 40/100\n",
      "7514/7514 [==============================] - 333s 44ms/step - loss: 2.6203\n",
      "Epoch 41/100\n",
      "7514/7514 [==============================] - 331s 44ms/step - loss: 2.5881\n",
      "Epoch 42/100\n",
      "7514/7514 [==============================] - 333s 44ms/step - loss: 2.5649\n",
      "Epoch 43/100\n",
      "7514/7514 [==============================] - 331s 44ms/step - loss: 2.5324\n",
      "Epoch 44/100\n",
      "7514/7514 [==============================] - 330s 44ms/step - loss: 2.5160\n",
      "Epoch 45/100\n",
      "7514/7514 [==============================] - 331s 44ms/step - loss: 2.4806\n",
      "Epoch 46/100\n",
      "7514/7514 [==============================] - 331s 44ms/step - loss: 2.4623\n",
      "Epoch 47/100\n",
      "7514/7514 [==============================] - 332s 44ms/step - loss: 2.4379\n",
      "Epoch 48/100\n",
      "7514/7514 [==============================] - 331s 44ms/step - loss: 2.4071\n",
      "Epoch 49/100\n",
      "7514/7514 [==============================] - 331s 44ms/step - loss: 2.3895\n",
      "Epoch 50/100\n",
      "7514/7514 [==============================] - 332s 44ms/step - loss: 2.3703\n",
      "Epoch 51/100\n",
      "7514/7514 [==============================] - 332s 44ms/step - loss: 2.3577\n",
      "Epoch 52/100\n",
      "7514/7514 [==============================] - 331s 44ms/step - loss: 2.3292\n",
      "Epoch 53/100\n",
      "7514/7514 [==============================] - 331s 44ms/step - loss: 2.3140\n",
      "Epoch 54/100\n",
      "7514/7514 [==============================] - 332s 44ms/step - loss: 2.2838\n",
      "Epoch 55/100\n",
      "7514/7514 [==============================] - 334s 44ms/step - loss: 2.2729\n",
      "Epoch 56/100\n",
      "7514/7514 [==============================] - 331s 44ms/step - loss: 2.2592\n",
      "Epoch 57/100\n",
      "7514/7514 [==============================] - 332s 44ms/step - loss: 2.2449\n",
      "Epoch 58/100\n",
      "7514/7514 [==============================] - 332s 44ms/step - loss: 2.2170\n",
      "Epoch 59/100\n",
      "7514/7514 [==============================] - 334s 44ms/step - loss: 2.2007\n",
      "Epoch 60/100\n",
      "7514/7514 [==============================] - 331s 44ms/step - loss: 2.1847\n",
      "Epoch 61/100\n",
      "7514/7514 [==============================] - 332s 44ms/step - loss: 2.1797\n",
      "Epoch 62/100\n",
      "7514/7514 [==============================] - 332s 44ms/step - loss: 2.1394\n",
      "Epoch 63/100\n",
      "7514/7514 [==============================] - 334s 44ms/step - loss: 2.1468\n",
      "Epoch 64/100\n",
      "7514/7514 [==============================] - 332s 44ms/step - loss: 2.1166\n",
      "Epoch 65/100\n",
      "7514/7514 [==============================] - 332s 44ms/step - loss: 2.1102\n",
      "Epoch 66/100\n",
      "7514/7514 [==============================] - 333s 44ms/step - loss: 2.0874\n",
      "Epoch 67/100\n",
      "7514/7514 [==============================] - 332s 44ms/step - loss: 2.0870\n",
      "Epoch 68/100\n",
      "7514/7514 [==============================] - 331s 44ms/step - loss: 2.0606\n",
      "Epoch 69/100\n",
      "7514/7514 [==============================] - 332s 44ms/step - loss: 2.0643\n",
      "Epoch 70/100\n",
      "7514/7514 [==============================] - 333s 44ms/step - loss: 2.0297\n",
      "Epoch 71/100\n",
      "7514/7514 [==============================] - 333s 44ms/step - loss: 2.0391\n",
      "Epoch 72/100\n",
      "7514/7514 [==============================] - 332s 44ms/step - loss: 2.0050\n",
      "Epoch 73/100\n",
      "7514/7514 [==============================] - 332s 44ms/step - loss: 2.0069\n",
      "Epoch 74/100\n",
      "7514/7514 [==============================] - 331s 44ms/step - loss: 1.9888\n",
      "Epoch 75/100\n",
      "7514/7514 [==============================] - 333s 44ms/step - loss: 1.9775\n",
      "Epoch 76/100\n",
      "7514/7514 [==============================] - 332s 44ms/step - loss: 1.9516\n",
      "Epoch 77/100\n",
      "7514/7514 [==============================] - 332s 44ms/step - loss: 1.9534\n",
      "Epoch 78/100\n",
      "7514/7514 [==============================] - 331s 44ms/step - loss: 1.9284\n",
      "Epoch 79/100\n",
      "7514/7514 [==============================] - 334s 44ms/step - loss: 1.9257\n",
      "Epoch 80/100\n",
      "7514/7514 [==============================] - 332s 44ms/step - loss: 1.9161\n",
      "Epoch 81/100\n",
      "7514/7514 [==============================] - 332s 44ms/step - loss: 1.9006\n",
      "Epoch 82/100\n",
      "7514/7514 [==============================] - 331s 44ms/step - loss: 1.8960\n",
      "Epoch 83/100\n",
      "7514/7514 [==============================] - 331s 44ms/step - loss: 1.8834\n",
      "Epoch 84/100\n",
      "7514/7514 [==============================] - 333s 44ms/step - loss: 1.8665\n",
      "Epoch 85/100\n",
      "7514/7514 [==============================] - 331s 44ms/step - loss: 1.8709\n",
      "Epoch 86/100\n",
      "7514/7514 [==============================] - 332s 44ms/step - loss: 1.8427\n",
      "Epoch 87/100\n",
      "7514/7514 [==============================] - 332s 44ms/step - loss: 1.8408\n",
      "Epoch 88/100\n",
      "7514/7514 [==============================] - 332s 44ms/step - loss: 1.8332\n",
      "Epoch 89/100\n",
      "7514/7514 [==============================] - 332s 44ms/step - loss: 1.8204\n",
      "Epoch 90/100\n",
      "7514/7514 [==============================] - 332s 44ms/step - loss: 1.8057\n",
      "Epoch 91/100\n",
      "7514/7514 [==============================] - 332s 44ms/step - loss: 1.8180\n",
      "Epoch 92/100\n",
      "7514/7514 [==============================] - 335s 45ms/step - loss: 1.7986\n",
      "Epoch 93/100\n",
      "7514/7514 [==============================] - 332s 44ms/step - loss: 1.7943\n",
      "Epoch 94/100\n",
      "7514/7514 [==============================] - 332s 44ms/step - loss: 1.7805\n",
      "Epoch 95/100\n",
      "7514/7514 [==============================] - 334s 44ms/step - loss: 1.7637\n",
      "Epoch 96/100\n",
      "7514/7514 [==============================] - 332s 44ms/step - loss: 1.7678\n",
      "Epoch 97/100\n",
      "7514/7514 [==============================] - 332s 44ms/step - loss: 1.7482\n",
      "Epoch 98/100\n",
      "7514/7514 [==============================] - 332s 44ms/step - loss: 1.7514\n",
      "Epoch 99/100\n",
      "7514/7514 [==============================] - 332s 44ms/step - loss: 1.7366\n",
      "Epoch 100/100\n",
      "7514/7514 [==============================] - 333s 44ms/step - loss: 1.7147\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_modified, Y_modified, epochs=100, batch_size=50)\n",
    "\n",
    "model.save_weights('text_generator_400_0.2_400_0.2_400_0.2_100.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_mapped = X[98]\n",
    "full_string = [n_to_char[value] for value in string_mapped]\n",
    "# generating characters\n",
    "for i in range(200):\n",
    "    x = np.reshape(string_mapped,(1,len(string_mapped), 1))\n",
    "    x = x / float(len(characters))\n",
    "\n",
    "    pred_index = np.argmax(model.predict(x, verbose=0))\n",
    "    seq = [n_to_char[value] for value in string_mapped]\n",
    "    full_string.append(n_to_char[pred_index])\n",
    "\n",
    "    string_mapped.append(pred_index)\n",
    "    string_mapped = string_mapped[1:len(string_mapped)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ifferent flowers. a room with a cobblestone ring around the walls, with rails on top of it, and ladd of the cenler ald a chest and a chest and a chest and a chest and a chest and a chest and a chest and a chest and a chest and a chest and a chest and a chest and a chest and a chest and a chest and a'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#combining text\n",
    "\n",
    "txt=\"\"\n",
    "for char in full_string:\n",
    "    txt = txt+char\n",
    "    \n",
    "txt    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying a different method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import sys\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess function\n",
    "# make all lowercase\n",
    "# tokenize\n",
    "# remove stop words\n",
    "\n",
    "def tokenize_words(input):\n",
    "    # lowercase everything to standardize it\n",
    "    input = input.lower()\n",
    "\n",
    "    # instantiate the tokenizer\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(input)\n",
    "\n",
    "    # if the created token isn't in the stop words, make it part of \"filtered\"\n",
    "    filtered = filter(lambda token: token not in stopwords.words('english'), tokens)\n",
    "    return \" \".join(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "text = df[\"Description\"].str.cat(sep=' ')\n",
    "\n",
    "# preprocess the input data using tokenize function\n",
    "processed_text = tokenize_words(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort unique characters, then use enumerate to get numbers\n",
    "# create a dictionary for the characters and their equivalent numbers\n",
    "\n",
    "text_chars = sorted(list(set(processed_text)))\n",
    "char_to_num = dict((c, i) for i, c in enumerate(text_chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of characters in text: 5228\n",
      "Total vocab in text: 31\n"
     ]
    }
   ],
   "source": [
    "# store variables for use later\n",
    "\n",
    "input_len_text = len(processed_text)\n",
    "vocab_len_text = len(text_chars)\n",
    "print (\"Total number of characters in text:\", input_len_text)\n",
    "print (\"Total vocab in text:\", vocab_len_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set sequence length (one complete mapping of inputs characters as integers)\n",
    "\n",
    "seq_length = 100\n",
    "x_data = []\n",
    "y_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all characters in input to numbers\n",
    "\n",
    "# loop through inputs, start at the beginning and go until we hit the final character \n",
    "# we can create a sequence out of\n",
    "\n",
    "for i in range(0, input_len_text - seq_length, 1):\n",
    "    # Define input and output sequences\n",
    "    # Input is the current character plus desired sequence length\n",
    "    in_seq = processed_text[i:i + seq_length]\n",
    "\n",
    "    # Out sequence is the initial character plus total sequence length\n",
    "    out_seq = processed_text[i + seq_length]\n",
    "\n",
    "    # We now convert list of characters to integers based on\n",
    "    # previously and add the values to our lists\n",
    "    x_data.append([char_to_num[char] for char in in_seq])\n",
    "    y_data.append(char_to_num[out_seq])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns: 5128\n"
     ]
    }
   ],
   "source": [
    "# check total number of sequences\n",
    "\n",
    "n_patterns = len(x_data)\n",
    "print (\"Total Patterns:\", n_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to numpy array, then make sure values are floats\n",
    "\n",
    "X = numpy.reshape(x_data, (n_patterns, seq_length, 1))\n",
    "X = X/float(vocab_len_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encode the labeled data\n",
    "\n",
    "y = np_utils.to_categorical(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create LSTM model and add layers, adding dropout to prevent overfitting\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(400, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(400, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(400))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model, now ready for training\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create checkpoints \n",
    "\n",
    "filepath = \"model_weights_saved.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "desired_callbacks = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5128/5128 [==============================] - 247s 48ms/step - loss: 3.0692\n",
      "\n",
      "Epoch 00001: loss improved from inf to 3.06922, saving model to model_weights_saved.hdf5\n",
      "Epoch 2/50\n",
      "5128/5128 [==============================] - 218s 42ms/step - loss: 2.9213\n",
      "\n",
      "Epoch 00002: loss improved from 3.06922 to 2.92133, saving model to model_weights_saved.hdf5\n",
      "Epoch 3/50\n",
      "5128/5128 [==============================] - 226s 44ms/step - loss: 2.9057\n",
      "\n",
      "Epoch 00003: loss improved from 2.92133 to 2.90568, saving model to model_weights_saved.hdf5\n",
      "Epoch 4/50\n",
      "5128/5128 [==============================] - 221s 43ms/step - loss: 2.8986\n",
      "\n",
      "Epoch 00004: loss improved from 2.90568 to 2.89864, saving model to model_weights_saved.hdf5\n",
      "Epoch 5/50\n",
      "5128/5128 [==============================] - 220s 43ms/step - loss: 2.9040\n",
      "\n",
      "Epoch 00005: loss did not improve from 2.89864\n",
      "Epoch 6/50\n",
      "5128/5128 [==============================] - 233s 45ms/step - loss: 2.8952\n",
      "\n",
      "Epoch 00006: loss improved from 2.89864 to 2.89524, saving model to model_weights_saved.hdf5\n",
      "Epoch 7/50\n",
      "5128/5128 [==============================] - 237s 46ms/step - loss: 2.8931\n",
      "\n",
      "Epoch 00007: loss improved from 2.89524 to 2.89315, saving model to model_weights_saved.hdf5\n",
      "Epoch 8/50\n",
      "5128/5128 [==============================] - 221s 43ms/step - loss: 2.8949\n",
      "\n",
      "Epoch 00008: loss did not improve from 2.89315\n",
      "Epoch 9/50\n",
      "5128/5128 [==============================] - 229s 45ms/step - loss: 2.8911\n",
      "\n",
      "Epoch 00009: loss improved from 2.89315 to 2.89114, saving model to model_weights_saved.hdf5\n",
      "Epoch 10/50\n",
      "5128/5128 [==============================] - 249s 49ms/step - loss: 2.8898\n",
      "\n",
      "Epoch 00010: loss improved from 2.89114 to 2.88980, saving model to model_weights_saved.hdf5\n",
      "Epoch 11/50\n",
      "5128/5128 [==============================] - 230s 45ms/step - loss: 2.8884\n",
      "\n",
      "Epoch 00011: loss improved from 2.88980 to 2.88836, saving model to model_weights_saved.hdf5\n",
      "Epoch 12/50\n",
      "5128/5128 [==============================] - 190s 37ms/step - loss: 2.8818\n",
      "\n",
      "Epoch 00012: loss improved from 2.88836 to 2.88184, saving model to model_weights_saved.hdf5\n",
      "Epoch 13/50\n",
      "5128/5128 [==============================] - 189s 37ms/step - loss: 2.8870\n",
      "\n",
      "Epoch 00013: loss did not improve from 2.88184\n",
      "Epoch 14/50\n",
      "5128/5128 [==============================] - 186s 36ms/step - loss: 2.8681\n",
      "\n",
      "Epoch 00014: loss improved from 2.88184 to 2.86808, saving model to model_weights_saved.hdf5\n",
      "Epoch 15/50\n",
      "5128/5128 [==============================] - 190s 37ms/step - loss: 2.8378\n",
      "\n",
      "Epoch 00015: loss improved from 2.86808 to 2.83777, saving model to model_weights_saved.hdf5\n",
      "Epoch 16/50\n",
      "5128/5128 [==============================] - 189s 37ms/step - loss: 2.8222\n",
      "\n",
      "Epoch 00016: loss improved from 2.83777 to 2.82219, saving model to model_weights_saved.hdf5\n",
      "Epoch 17/50\n",
      "5128/5128 [==============================] - 185s 36ms/step - loss: 2.8055\n",
      "\n",
      "Epoch 00017: loss improved from 2.82219 to 2.80546, saving model to model_weights_saved.hdf5\n",
      "Epoch 18/50\n",
      "5128/5128 [==============================] - 188s 37ms/step - loss: 2.7811\n",
      "\n",
      "Epoch 00018: loss improved from 2.80546 to 2.78112, saving model to model_weights_saved.hdf5\n",
      "Epoch 19/50\n",
      "5128/5128 [==============================] - 189s 37ms/step - loss: 2.7646\n",
      "\n",
      "Epoch 00019: loss improved from 2.78112 to 2.76458, saving model to model_weights_saved.hdf5\n",
      "Epoch 20/50\n",
      "5128/5128 [==============================] - 186s 36ms/step - loss: 2.7030\n",
      "\n",
      "Epoch 00020: loss improved from 2.76458 to 2.70300, saving model to model_weights_saved.hdf5\n",
      "Epoch 21/50\n",
      "5128/5128 [==============================] - 176s 34ms/step - loss: 2.6641\n",
      "\n",
      "Epoch 00021: loss improved from 2.70300 to 2.66411, saving model to model_weights_saved.hdf5\n",
      "Epoch 22/50\n",
      "5128/5128 [==============================] - 183s 36ms/step - loss: 2.6228\n",
      "\n",
      "Epoch 00022: loss improved from 2.66411 to 2.62276, saving model to model_weights_saved.hdf5\n",
      "Epoch 23/50\n",
      "5128/5128 [==============================] - 178s 35ms/step - loss: 2.6027\n",
      "\n",
      "Epoch 00023: loss improved from 2.62276 to 2.60265, saving model to model_weights_saved.hdf5\n",
      "Epoch 24/50\n",
      "5128/5128 [==============================] - 181s 35ms/step - loss: 2.5719\n",
      "\n",
      "Epoch 00024: loss improved from 2.60265 to 2.57186, saving model to model_weights_saved.hdf5\n",
      "Epoch 25/50\n",
      "5128/5128 [==============================] - 186s 36ms/step - loss: 2.5337\n",
      "\n",
      "Epoch 00025: loss improved from 2.57186 to 2.53366, saving model to model_weights_saved.hdf5\n",
      "Epoch 26/50\n",
      "5128/5128 [==============================] - 187s 36ms/step - loss: 2.4947\n",
      "\n",
      "Epoch 00026: loss improved from 2.53366 to 2.49473, saving model to model_weights_saved.hdf5\n",
      "Epoch 27/50\n",
      "5128/5128 [==============================] - 187s 36ms/step - loss: 2.4479\n",
      "\n",
      "Epoch 00027: loss improved from 2.49473 to 2.44793, saving model to model_weights_saved.hdf5\n",
      "Epoch 28/50\n",
      "5128/5128 [==============================] - 190s 37ms/step - loss: 2.3950\n",
      "\n",
      "Epoch 00028: loss improved from 2.44793 to 2.39501, saving model to model_weights_saved.hdf5\n",
      "Epoch 29/50\n",
      "5128/5128 [==============================] - 164s 32ms/step - loss: 2.3667\n",
      "\n",
      "Epoch 00029: loss improved from 2.39501 to 2.36671, saving model to model_weights_saved.hdf5\n",
      "Epoch 30/50\n",
      "5128/5128 [==============================] - 155s 30ms/step - loss: 2.3217\n",
      "\n",
      "Epoch 00030: loss improved from 2.36671 to 2.32166, saving model to model_weights_saved.hdf5\n",
      "Epoch 31/50\n",
      "5128/5128 [==============================] - 159s 31ms/step - loss: 2.2817\n",
      "\n",
      "Epoch 00031: loss improved from 2.32166 to 2.28170, saving model to model_weights_saved.hdf5\n",
      "Epoch 32/50\n",
      "5128/5128 [==============================] - 156s 30ms/step - loss: 2.2278\n",
      "\n",
      "Epoch 00032: loss improved from 2.28170 to 2.22781, saving model to model_weights_saved.hdf5\n",
      "Epoch 33/50\n",
      "5128/5128 [==============================] - 158s 31ms/step - loss: 2.1684\n",
      "\n",
      "Epoch 00033: loss improved from 2.22781 to 2.16844, saving model to model_weights_saved.hdf5\n",
      "Epoch 34/50\n",
      "5128/5128 [==============================] - 155s 30ms/step - loss: 2.1279\n",
      "\n",
      "Epoch 00034: loss improved from 2.16844 to 2.12795, saving model to model_weights_saved.hdf5\n",
      "Epoch 35/50\n",
      "5128/5128 [==============================] - 157s 31ms/step - loss: 2.0543\n",
      "\n",
      "Epoch 00035: loss improved from 2.12795 to 2.05426, saving model to model_weights_saved.hdf5\n",
      "Epoch 36/50\n",
      "5128/5128 [==============================] - 146s 29ms/step - loss: 1.9850\n",
      "\n",
      "Epoch 00036: loss improved from 2.05426 to 1.98503, saving model to model_weights_saved.hdf5\n",
      "Epoch 37/50\n",
      "5128/5128 [==============================] - 156s 30ms/step - loss: 1.9300\n",
      "\n",
      "Epoch 00037: loss improved from 1.98503 to 1.93003, saving model to model_weights_saved.hdf5\n",
      "Epoch 38/50\n",
      "5128/5128 [==============================] - 175s 34ms/step - loss: 1.8483\n",
      "\n",
      "Epoch 00038: loss improved from 1.93003 to 1.84833, saving model to model_weights_saved.hdf5\n",
      "Epoch 39/50\n",
      "5128/5128 [==============================] - 152s 30ms/step - loss: 1.7750\n",
      "\n",
      "Epoch 00039: loss improved from 1.84833 to 1.77498, saving model to model_weights_saved.hdf5\n",
      "Epoch 40/50\n",
      "5128/5128 [==============================] - 156s 30ms/step - loss: 1.7091\n",
      "\n",
      "Epoch 00040: loss improved from 1.77498 to 1.70907, saving model to model_weights_saved.hdf5\n",
      "Epoch 41/50\n",
      "5128/5128 [==============================] - 149s 29ms/step - loss: 1.5902\n",
      "\n",
      "Epoch 00041: loss improved from 1.70907 to 1.59020, saving model to model_weights_saved.hdf5\n",
      "Epoch 42/50\n",
      "5128/5128 [==============================] - 166s 32ms/step - loss: 1.5014\n",
      "\n",
      "Epoch 00042: loss improved from 1.59020 to 1.50143, saving model to model_weights_saved.hdf5\n",
      "Epoch 43/50\n",
      "5128/5128 [==============================] - 162s 32ms/step - loss: 1.4459\n",
      "\n",
      "Epoch 00043: loss improved from 1.50143 to 1.44589, saving model to model_weights_saved.hdf5\n",
      "Epoch 44/50\n",
      "5128/5128 [==============================] - 163s 32ms/step - loss: 1.3846\n",
      "\n",
      "Epoch 00044: loss improved from 1.44589 to 1.38456, saving model to model_weights_saved.hdf5\n",
      "Epoch 45/50\n",
      "5128/5128 [==============================] - 167s 32ms/step - loss: 1.2644\n",
      "\n",
      "Epoch 00045: loss improved from 1.38456 to 1.26438, saving model to model_weights_saved.hdf5\n",
      "Epoch 46/50\n",
      "5128/5128 [==============================] - 171s 33ms/step - loss: 1.1230\n",
      "\n",
      "Epoch 00046: loss improved from 1.26438 to 1.12304, saving model to model_weights_saved.hdf5\n",
      "Epoch 47/50\n",
      "5128/5128 [==============================] - 166s 32ms/step - loss: 1.1008\n",
      "\n",
      "Epoch 00047: loss improved from 1.12304 to 1.10082, saving model to model_weights_saved.hdf5\n",
      "Epoch 48/50\n",
      "5128/5128 [==============================] - 163s 32ms/step - loss: 1.0161\n",
      "\n",
      "Epoch 00048: loss improved from 1.10082 to 1.01610, saving model to model_weights_saved.hdf5\n",
      "Epoch 49/50\n",
      "5128/5128 [==============================] - 165s 32ms/step - loss: 0.9883\n",
      "\n",
      "Epoch 00049: loss improved from 1.01610 to 0.98829, saving model to model_weights_saved.hdf5\n",
      "Epoch 50/50\n",
      "5128/5128 [==============================] - 164s 32ms/step - loss: 0.9326\n",
      "\n",
      "Epoch 00050: loss improved from 0.98829 to 0.93256, saving model to model_weights_saved.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb3f6386a0>"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model and let it train\n",
    "\n",
    "model.fit(X, y, epochs=50, batch_size=256, callbacks=desired_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load weights back in and recompile model\n",
    "\n",
    "filename = \"model_weights_saved.hdf5\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert output back to characters\n",
    "\n",
    "num_to_char = dict((i, c) for i, c in enumerate(text_chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start with random seed to generate sequence of characters from\n",
    "# create 150 room descriptions from random seed\n",
    "\n",
    "descriptions = []\n",
    "for _ in range(150):\n",
    "    start = numpy.random.randint(0, len(x_data) - 1)\n",
    "    pattern = x_data[start]\n",
    "    description = ''.join([num_to_char[value] for value in pattern])\n",
    "    descriptions.append(description)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ccess top wool ring trapped chest surrounded two tnt blocks containing two ender pearls trap sprung ', 'irs two chandeliers hang ceiling two vindicators evoker always generate large library study room thr', 'enerates room bunch arches made dark oak logs chest exists room end containing loot vindicator alway', 'eon otherwise empty room containing illager pixel art stairs leading decorated illager head made woo', 'h 5 flower pots placed containing different flowers room cobblestone ring around walls rails top lad', ' vindicator always generates room spiral staircase 1 wide dead end sloping curving hallway leads sin', 'potted alliums full cauldron chest containing alliums sit nearby roof made oak fences altar like roo', 'rner chandelier hangs ceiling long bedroom pink purple beds towards rear table flower pot corner two', 'op ladders placed walls ring single carved pumpkin sits wall facing door room two types tables made ', 'fountain surrounded andesite opposite corner dark oak tree large dining hall multiple three chair ta']\n"
     ]
    }
   ],
   "source": [
    "# check out results\n",
    "\n",
    "print(descriptions[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save list of descriptions as text file to use in adventure game\n",
    "\n",
    "with open(\"descriptions.txt\", \"w\") as output:\n",
    "    output.write(str(descriptions))\n",
    "    \n",
    "import json  \n",
    "\n",
    "with open(\"desc_json.txt\", \"w\") as output:\n",
    "    json.dump(descriptions, output)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now repeat process with names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "names = df[\"Structure name\"].str.cat(sep=' ')\n",
    "\n",
    "# preprocess data using tokenize function from above\n",
    "processed_names = tokenize_words(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort unique characters, then use enumerate to get numbers\n",
    "# create a dictionary for the characters and their equivalent numbers\n",
    "\n",
    "name_chars = sorted(list(set(processed_names)))\n",
    "char_to_num_name = dict((c, i) for i, c in enumerate(name_chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of characters in names: 817\n",
      "Total vocab in names: 25\n"
     ]
    }
   ],
   "source": [
    "# store variables for use later\n",
    "\n",
    "input_len_names = len(processed_names)\n",
    "vocab_len_names = len(name_chars)\n",
    "print (\"Total number of characters in names:\", input_len_names)\n",
    "print (\"Total vocab in names:\", vocab_len_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set sequence length (one complete mapping of inputs characters as integers)\n",
    "\n",
    "seq_length = 50\n",
    "x_data = []\n",
    "y_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all characters in input to numbers\n",
    "\n",
    "# loop through inputs, start at the beginning and go until we hit the final character \n",
    "# we can create a sequence out of\n",
    "\n",
    "for i in range(0, input_len_names - seq_length, 1):\n",
    "    # Define input and output sequences\n",
    "    # Input is the current character plus desired sequence length\n",
    "    in_seq = processed_names[i:i + seq_length]\n",
    "\n",
    "    # Out sequence is the initial character plus total sequence length\n",
    "    out_seq = processed_names[i + seq_length]\n",
    "\n",
    "    # We now convert list of characters to integers based on\n",
    "    # previously and add the values to our lists\n",
    "    x_data.append([char_to_num_name[char] for char in in_seq])\n",
    "    y_data.append(char_to_num_name[out_seq])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns: 1534\n"
     ]
    }
   ],
   "source": [
    "# check total number of sequences\n",
    "\n",
    "n_patterns = len(x_data)\n",
    "print (\"Total Patterns:\", n_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to numpy array, then make sure values are floats\n",
    "\n",
    "X = numpy.reshape(x_data, (n_patterns, seq_length, 1))\n",
    "X = X/float(vocab_len_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encode the labeled data\n",
    "\n",
    "y = np_utils.to_categorical(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create LSTM model and add layers, adding dropout to prevent overfitting\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(400, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(400, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(400))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model, now ready for training\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create checkpoints \n",
    "\n",
    "filepath = \"model_weights_saved.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "desired_callbacks = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1534/1534 [==============================] - 31s 20ms/step - loss: 3.2552\n",
      "\n",
      "Epoch 00001: loss improved from inf to 3.25520, saving model to model_weights_saved.hdf5\n",
      "Epoch 2/50\n",
      "1534/1534 [==============================] - 28s 18ms/step - loss: 3.0774\n",
      "\n",
      "Epoch 00002: loss improved from 3.25520 to 3.07743, saving model to model_weights_saved.hdf5\n",
      "Epoch 3/50\n",
      "1534/1534 [==============================] - 28s 18ms/step - loss: 3.0550\n",
      "\n",
      "Epoch 00003: loss improved from 3.07743 to 3.05503, saving model to model_weights_saved.hdf5\n",
      "Epoch 4/50\n",
      "1534/1534 [==============================] - 24s 16ms/step - loss: 3.0350\n",
      "\n",
      "Epoch 00004: loss improved from 3.05503 to 3.03498, saving model to model_weights_saved.hdf5\n",
      "Epoch 5/50\n",
      "1534/1534 [==============================] - 28s 18ms/step - loss: 3.0253\n",
      "\n",
      "Epoch 00005: loss improved from 3.03498 to 3.02531, saving model to model_weights_saved.hdf5\n",
      "Epoch 6/50\n",
      "1534/1534 [==============================] - 26s 17ms/step - loss: 3.0146\n",
      "\n",
      "Epoch 00006: loss improved from 3.02531 to 3.01464, saving model to model_weights_saved.hdf5\n",
      "Epoch 7/50\n",
      "1534/1534 [==============================] - 28s 18ms/step - loss: 2.9751\n",
      "\n",
      "Epoch 00007: loss improved from 3.01464 to 2.97514, saving model to model_weights_saved.hdf5\n",
      "Epoch 8/50\n",
      "1534/1534 [==============================] - 25s 17ms/step - loss: 2.9498\n",
      "\n",
      "Epoch 00008: loss improved from 2.97514 to 2.94979, saving model to model_weights_saved.hdf5\n",
      "Epoch 9/50\n",
      "1534/1534 [==============================] - 23s 15ms/step - loss: 2.8970\n",
      "\n",
      "Epoch 00009: loss improved from 2.94979 to 2.89701, saving model to model_weights_saved.hdf5\n",
      "Epoch 10/50\n",
      "1534/1534 [==============================] - 22s 15ms/step - loss: 2.8536\n",
      "\n",
      "Epoch 00010: loss improved from 2.89701 to 2.85357, saving model to model_weights_saved.hdf5\n",
      "Epoch 11/50\n",
      "1534/1534 [==============================] - 21s 14ms/step - loss: 2.8664\n",
      "\n",
      "Epoch 00011: loss did not improve from 2.85357\n",
      "Epoch 12/50\n",
      "1534/1534 [==============================] - 23s 15ms/step - loss: 2.8504\n",
      "\n",
      "Epoch 00012: loss improved from 2.85357 to 2.85039, saving model to model_weights_saved.hdf5\n",
      "Epoch 13/50\n",
      "1534/1534 [==============================] - 29s 19ms/step - loss: 2.8246\n",
      "\n",
      "Epoch 00013: loss improved from 2.85039 to 2.82460, saving model to model_weights_saved.hdf5\n",
      "Epoch 14/50\n",
      "1534/1534 [==============================] - 24s 16ms/step - loss: 2.8197\n",
      "\n",
      "Epoch 00014: loss improved from 2.82460 to 2.81967, saving model to model_weights_saved.hdf5\n",
      "Epoch 15/50\n",
      "1534/1534 [==============================] - 23s 15ms/step - loss: 2.8160\n",
      "\n",
      "Epoch 00015: loss improved from 2.81967 to 2.81599, saving model to model_weights_saved.hdf5\n",
      "Epoch 16/50\n",
      "1534/1534 [==============================] - 23s 15ms/step - loss: 2.8187\n",
      "\n",
      "Epoch 00016: loss did not improve from 2.81599\n",
      "Epoch 17/50\n",
      "1534/1534 [==============================] - 25s 16ms/step - loss: 2.8134\n",
      "\n",
      "Epoch 00017: loss improved from 2.81599 to 2.81339, saving model to model_weights_saved.hdf5\n",
      "Epoch 18/50\n",
      "1534/1534 [==============================] - 23s 15ms/step - loss: 2.8060\n",
      "\n",
      "Epoch 00018: loss improved from 2.81339 to 2.80601, saving model to model_weights_saved.hdf5\n",
      "Epoch 19/50\n",
      "1534/1534 [==============================] - 22s 14ms/step - loss: 2.7972\n",
      "\n",
      "Epoch 00019: loss improved from 2.80601 to 2.79722, saving model to model_weights_saved.hdf5\n",
      "Epoch 20/50\n",
      "1534/1534 [==============================] - 24s 16ms/step - loss: 2.7991\n",
      "\n",
      "Epoch 00020: loss did not improve from 2.79722\n",
      "Epoch 21/50\n",
      "1534/1534 [==============================] - 23s 15ms/step - loss: 2.7998\n",
      "\n",
      "Epoch 00021: loss did not improve from 2.79722\n",
      "Epoch 22/50\n",
      "1534/1534 [==============================] - 23s 15ms/step - loss: 2.8110\n",
      "\n",
      "Epoch 00022: loss did not improve from 2.79722\n",
      "Epoch 23/50\n",
      "1534/1534 [==============================] - 24s 15ms/step - loss: 2.7944\n",
      "\n",
      "Epoch 00023: loss improved from 2.79722 to 2.79438, saving model to model_weights_saved.hdf5\n",
      "Epoch 24/50\n",
      "1534/1534 [==============================] - 23s 15ms/step - loss: 2.8024\n",
      "\n",
      "Epoch 00024: loss did not improve from 2.79438\n",
      "Epoch 25/50\n",
      "1534/1534 [==============================] - 24s 16ms/step - loss: 2.7925\n",
      "\n",
      "Epoch 00025: loss improved from 2.79438 to 2.79250, saving model to model_weights_saved.hdf5\n",
      "Epoch 26/50\n",
      "1534/1534 [==============================] - 22s 14ms/step - loss: 2.7916\n",
      "\n",
      "Epoch 00026: loss improved from 2.79250 to 2.79161, saving model to model_weights_saved.hdf5\n",
      "Epoch 27/50\n",
      "1534/1534 [==============================] - 23s 15ms/step - loss: 2.8006\n",
      "\n",
      "Epoch 00027: loss did not improve from 2.79161\n",
      "Epoch 28/50\n",
      "1534/1534 [==============================] - 23s 15ms/step - loss: 2.8014\n",
      "\n",
      "Epoch 00028: loss did not improve from 2.79161\n",
      "Epoch 29/50\n",
      "1534/1534 [==============================] - 23s 15ms/step - loss: 2.7849\n",
      "\n",
      "Epoch 00029: loss improved from 2.79161 to 2.78495, saving model to model_weights_saved.hdf5\n",
      "Epoch 30/50\n",
      "1534/1534 [==============================] - 22s 14ms/step - loss: 2.7927\n",
      "\n",
      "Epoch 00030: loss did not improve from 2.78495\n",
      "Epoch 31/50\n",
      "1534/1534 [==============================] - 22s 15ms/step - loss: 2.7838\n",
      "\n",
      "Epoch 00031: loss improved from 2.78495 to 2.78383, saving model to model_weights_saved.hdf5\n",
      "Epoch 32/50\n",
      "1534/1534 [==============================] - 22s 14ms/step - loss: 2.7784\n",
      "\n",
      "Epoch 00032: loss improved from 2.78383 to 2.77839, saving model to model_weights_saved.hdf5\n",
      "Epoch 33/50\n",
      "1534/1534 [==============================] - 24s 16ms/step - loss: 2.7726\n",
      "\n",
      "Epoch 00033: loss improved from 2.77839 to 2.77259, saving model to model_weights_saved.hdf5\n",
      "Epoch 34/50\n",
      "1534/1534 [==============================] - 22s 14ms/step - loss: 2.7675\n",
      "\n",
      "Epoch 00034: loss improved from 2.77259 to 2.76753, saving model to model_weights_saved.hdf5\n",
      "Epoch 35/50\n",
      "1534/1534 [==============================] - 23s 15ms/step - loss: 2.7647\n",
      "\n",
      "Epoch 00035: loss improved from 2.76753 to 2.76473, saving model to model_weights_saved.hdf5\n",
      "Epoch 36/50\n",
      "1534/1534 [==============================] - 23s 15ms/step - loss: 2.7536\n",
      "\n",
      "Epoch 00036: loss improved from 2.76473 to 2.75363, saving model to model_weights_saved.hdf5\n",
      "Epoch 37/50\n",
      "1534/1534 [==============================] - 22s 14ms/step - loss: 2.7396\n",
      "\n",
      "Epoch 00037: loss improved from 2.75363 to 2.73959, saving model to model_weights_saved.hdf5\n",
      "Epoch 38/50\n",
      "1534/1534 [==============================] - 25s 17ms/step - loss: 2.7302\n",
      "\n",
      "Epoch 00038: loss improved from 2.73959 to 2.73016, saving model to model_weights_saved.hdf5\n",
      "Epoch 39/50\n",
      "1534/1534 [==============================] - 23s 15ms/step - loss: 2.7308\n",
      "\n",
      "Epoch 00039: loss did not improve from 2.73016\n",
      "Epoch 40/50\n",
      "1534/1534 [==============================] - 22s 15ms/step - loss: 2.7086\n",
      "\n",
      "Epoch 00040: loss improved from 2.73016 to 2.70856, saving model to model_weights_saved.hdf5\n",
      "Epoch 41/50\n",
      "1534/1534 [==============================] - 22s 14ms/step - loss: 2.6803\n",
      "\n",
      "Epoch 00041: loss improved from 2.70856 to 2.68032, saving model to model_weights_saved.hdf5\n",
      "Epoch 42/50\n",
      "1534/1534 [==============================] - 23s 15ms/step - loss: 2.6822\n",
      "\n",
      "Epoch 00042: loss did not improve from 2.68032\n",
      "Epoch 43/50\n",
      "1534/1534 [==============================] - 23s 15ms/step - loss: 2.7321\n",
      "\n",
      "Epoch 00043: loss did not improve from 2.68032\n",
      "Epoch 44/50\n",
      "1534/1534 [==============================] - 22s 15ms/step - loss: 2.6858\n",
      "\n",
      "Epoch 00044: loss did not improve from 2.68032\n",
      "Epoch 45/50\n",
      "1534/1534 [==============================] - 24s 16ms/step - loss: 2.6463\n",
      "\n",
      "Epoch 00045: loss improved from 2.68032 to 2.64626, saving model to model_weights_saved.hdf5\n",
      "Epoch 46/50\n",
      "1534/1534 [==============================] - 24s 16ms/step - loss: 2.6177\n",
      "\n",
      "Epoch 00046: loss improved from 2.64626 to 2.61775, saving model to model_weights_saved.hdf5\n",
      "Epoch 47/50\n",
      "1534/1534 [==============================] - 22s 14ms/step - loss: 2.5716\n",
      "\n",
      "Epoch 00047: loss improved from 2.61775 to 2.57159, saving model to model_weights_saved.hdf5\n",
      "Epoch 48/50\n",
      "1534/1534 [==============================] - 23s 15ms/step - loss: 2.5498\n",
      "\n",
      "Epoch 00048: loss improved from 2.57159 to 2.54979, saving model to model_weights_saved.hdf5\n",
      "Epoch 49/50\n",
      "1534/1534 [==============================] - 25s 16ms/step - loss: 2.5098\n",
      "\n",
      "Epoch 00049: loss improved from 2.54979 to 2.50975, saving model to model_weights_saved.hdf5\n",
      "Epoch 50/50\n",
      "1534/1534 [==============================] - 22s 14ms/step - loss: 2.4835\n",
      "\n",
      "Epoch 00050: loss improved from 2.50975 to 2.48354, saving model to model_weights_saved.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a4e380198>"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model and let it train\n",
    "\n",
    "model.fit(X, y, epochs=50, batch_size=256, callbacks=desired_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load weights back in and recompile model\n",
    "\n",
    "filename = \"model_weights_saved.hdf5\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert output back to characters\n",
    "\n",
    "num_to_char = dict((i, c) for i, c in enumerate(name_chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:\n",
      "nding stairway room \n"
     ]
    }
   ],
   "source": [
    "# start with random seed to generate sequence of characters from\n",
    "# create 150 room names from random seed\n",
    "\n",
    "start = numpy.random.randint(0, len(x_data) - 1)\n",
    "pattern = x_data[start]\n",
    "print(\"Random Seed:\")\n",
    "space = ''\n",
    "name = space.join([num_to_char[value] for value in pattern])\n",
    "print(name[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " bedroom medium library straight stairs room maste\n"
     ]
    }
   ],
   "source": [
    "room_list = [\"farm small empty\", \"obsidian room birch\", \"iple bed bedroom\", \"room large dining\", \"room single bed\", \"room x room spider\", \"redstone jail\", \"x room spider\", \"large dining room\", \"flower room rails\", \"room illager\", \"bed bedroom\", \"statue room nature\", \"tulip sanctuary\", \"ference room large\", \"small jail wood\", \"room obsidian\", \"stairway room\", ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save list of descriptions as text file to use in adventure game\n",
    "import json  \n",
    "\n",
    "with open(\"names.txt\", \"w\") as output:\n",
    "    json.dump(room_names, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
